{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Homework 5\n\nAuthor: BLANK\n\nCollaborators: BLANK\n\nThe main part of this week's homework is based on an example from Jake VanderPlas's book, [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/).\n\n## Part 0 - Downloading the data\n\nGo to [https://data.seattle.gov/](https://data.seattle.gov/) and find the \"Fremont Bridge Bicycle Counter\" dataset (**not** the one called \"Timeline\", the plain one).  Download the csv file for that dataset (click the \"Export\" button at the top right), and upload that csv file to this Deepnote project.  Rename the csv file to \"Fremont.csv\".  (You can click the three dots to the right of the file name, to reach the option to rename it.  Or just rename it on your computer before you upload the file.)\n\n## Part 1 - Worksheet on clustering (Optional)\n\nThis Part 1 is optional and worth up to **4 bonus points** in the Homework category.\n\nComplete either the Thursday or Friday worksheet (your choice) from Week 5 and upload it into this same project.  (So in your final submission, there should be 4 files in this project: `Fremont.csv`, `SeattleWeather.csv`, `Homework5.ipynb`, and one of the two completed worksheets.)",
   "metadata": {
    "cell_id": "72b2b6a38573496290e8378219eeedc4",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 560.78125
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Part 2 - Linear regression with Seattle bicycle data",
   "metadata": {
    "cell_id": "54c1bae545044b74a9a648dc4fe2fa5a",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 1\n\n* Read in the Fremont.csv file from Part 0, drop the rows which contain missing values, keep only the first two columns, and name the resulting DataFrame `df_pre`.\n* Rename the \"Fremont Bridge Total\" column to \"Bikes\".\n* Convert the \"Date\" column to a `datetime` data type by using `pd.to_datetime`.  (The exact `dtype` will be displayed as `datetime64[ns]`.  This step may take about 30 seconds.)\n* Using the `dt` accessor and two Boolean Series, define a new pandas DataFrame `df_pre2` which contains only the rows in `df_pre` from the year 2022 and from the hour 8:00am in the morning.  Use `.copy()` to ensure that `df_pre2` is a new DataFrame.\n* Round the \"Date\" column to the nearest date (i.e., lose the 8:00am part) by using the following code: `df_pre2[\"Date\"] = df_pre[\"Date\"].dt.round(\"d\")`\n* Check your answer: `df_pre2` should have 120 rows and 2 columns.",
   "metadata": {
    "cell_id": "b28482f691234a449f0a35a1e5fbe9a3",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 353.375
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 2\n\nThe weather data in the SeattleWeather.csv file was downloaded a few days ago from [this website](https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND).  (You don't need to re-download it; just use the provided csv file in this Deepnote project.)  The \"PRCP\" column in this csv file indicates the amount of precipitation that fell on that day.\n\n* Read in the contents of the SeattleWeather.csv file, drop the rows with missing data, and name the result `df_weather`.\n* Rename the \"DATE\" column to \"Date\".\n* Convert the \"Date\" column to a `datetime` data type.\n* Keep only the \"Date\" and \"PRCP\" columns in `df_weather`, for example, by using `df_weather = df_weather[???].copy()`.\n* Check your answer: the resulting DataFrame should have 116 rows and 2 columns, and the `dtypes` should be `datetime64[ns]` and `float64`.",
   "metadata": {
    "cell_id": "60a45b1da3244f708d6b209794abc274",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 341.984375
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 3\n\n* Using `merge` with type \"inner\", merge together `df_pre2` and `df_weather` on their \"Date\" columns.  (See [this week's videos](https://youtube.com/playlist?list=PLHfGN68wSbbLgfe20jFxjEunvPVHiaQ6I) for information on `merge`.)  Name the resulting DataFrame `df`.\n* The resulting DataFrame `df` should have 116 rows and 3 columns.",
   "metadata": {
    "cell_id": "5438bca5b39941d18565841873f96504",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 162.1875
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 4\n\n* Midterm 1 Review: `pd.to_datetime(\"2022-05-02\").day_name()` is \"Monday\".  Using this idea, list comprehension, and f-strings, make the length 7 list `[\"Monday\", \"Tuesday\", ..., \"Saturday\", \"Sunday\"]` and save it with the variable name `days`.\n* Add 7 columns to `df` with the names \"Monday\", ..., \"Sunday\", and fill in all the values with `0`.  (This is easier than it sounds.  Just use `df[days] = 0`.)\n* `df` should now have 10 columns.",
   "metadata": {
    "cell_id": "1a0a6a0352134001a3a82f89948059b9",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 232.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 5\n\n* Add a new column called \"DayName\" to `df` that contains the day name for that row.  For example, January 1st of this year was a Saturday, so the initial value in the \"DayName\" column should be \"Saturday\".  (Suggestion: use `df[\"DayName\"] = df[\"Date\"].map(???)`.)\n* Add a new column called \"Month\" to `df` that contains the numerical month number.  Use the `dt` accessor again.",
   "metadata": {
    "cell_id": "bbbae674e442447ab882229eb6072e81",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 184.59375
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 6\n\n* If we want to know which rows correspond to \"Monday\", we can use `df[\"DayName\"] == \"Monday\"`.\n* If we want to set the value in the \"Monday\" column of those rows to `1`, we can use `df.loc[df[\"DayName\"] == \"Monday\", \"Monday\"] = 1`.\n* Using that idea, a for loop, and the `days` list from above, set the \"Monday\" column of all \"Monday\" rows to 1, set the \"Tuesday\" column of all \"Tuesday\" rows to 1, etc.\n* Check your answer.  If you evaluate `df[days].sum(axis=0)`, you should see that there are 17 Mondays and 16 Thursdays.  (One Sunday value seems to be missing.)",
   "metadata": {
    "cell_id": "184bd8e256824631bc719956e988409a",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 257.78125
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 7\n\n* Create a scikit-learn `LinearRegression` object `reg`.  When you create `reg`, specify the keyword argument `fit_intercept=False`.  (For this particular data, allowing an intercept value gives no extra flexibility.)\n* Define a length 9 list `cols` containing \"PRCP\", \"Month\", and all the days from the `days` list.\n* Fit `reg` using `cols` for the input variables, and using \"Bikes\" for the output variable.\n* Add a \"Pred\" column to `df` containing the `reg.predict` values.",
   "metadata": {
    "cell_id": "b47fb9b61cef40518085e3947a3fa0d3",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 212.984375
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 8\n\n* Check the values of the fitted coefficients using `pd.Series(???, index=cols)`.\n* Is the \"PRCP\" value positive or negative?  Does this make sense?\n* Which day do the most people bike?  Which day do the fewest?\n* Do people tend to bike more or less as the months change from January to April?\n* Why might the results get less accurate with respect to the month coefficient if our data contained all months from January to December?",
   "metadata": {
    "cell_id": "c7aebfed57634076931e694be56ac485",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 238.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 9\n\nTo make an Altair chart `c` containing the actual data in the DataFrame, you can use the following code.\n\n```\nsel = alt.selection_single(fields=[\"DayName\"])\n\nc = alt.Chart(df).mark_circle().encode(\n    x=\"Date\",\n    y=\"Bikes\",\n    tooltip=[\"Bikes\", \"Date\", \"DayName\", \"PRCP\"],\n    size=alt.condition(sel, alt.value(40),alt.value(10))\n).add_selection(sel)\n```\n\n* Define that chart `c` and then display it.\n* Try clicking on one of the points.  What change happens?  (Why are some points selected but not others?)\n* What 3 parts of this Altair code are necessary for this interactivity to work?",
   "metadata": {
    "cell_id": "de6d4a0ca6a248fe9f05edd72f6e40b2",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 390.96875
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 10\n\n* Define a second chart `c1` which is a line chart instead of a scatter plot; which uses `color=\"red\"` as a `mark_line()` argument; which again uses \"Date\" for the x-axis; and which uses the predicted value instead of the actual value for the y-coordinate.\n* Display a layered chart of `c` and `c1` using `c+c1`.",
   "metadata": {
    "cell_id": "af4a37ee16c049c384ad2a3f12b3393c",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 184.59375
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Question 11\n\n* The red curve represents a linear function, but it certainly doesn't look linear.  Why isn't that a contradiction?\n* There are frequent lower dips in the red curve.  What do those local minima represent?  (In other words, why do you think our function has learned to have local minima in those spots?)",
   "metadata": {
    "cell_id": "2cabb7ec31354db7b15cf3e9d6191c1d",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 162.1875
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Submission\n\nTo submit this homework, go to the Share option at the top right, and share the project to create a link, and then submit that link on Canvas.",
   "metadata": {
    "cell_id": "8b8ad0375fe548d4859a280471940ef8",
    "tags": [],
    "owner_user_id": "02be19f8-8497-4212-b8d0-46ca9f1d48b9",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 130.796875
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=55779e20-5666-45ba-be3f-92b471b3743f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "1279643e-406c-4e25-8e62-6fa37065cc3e",
  "deepnote_execution_queue": []
 }
}